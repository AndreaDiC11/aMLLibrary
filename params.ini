# different input options:

[General]
run_num = 1

[DataPreparation]
target_column = 28
# input_name = kmeans
input_name = tf_deepspeech
split = split2
case = case1
use_spark_info = False
# input_path = P8_kmeans.csv
# input_path = tf_deepspeech_originale_0.csv
input_path = P600_GT750.csv
# the main result path should exist
result_path = ./results/
# irrelevant_column_name = ['run']
# irrelevant_column_name = ['starting timestamp(0)', 'starting time(1)', 'tensorflow version(2)', 'system_UUID(3)',
#                        'mac_address(4)', 'vm_instance(5)', 'GPU type(6)', 'Network Type(10)', 'classes(12)',
#                        'Iterations Fraction(14)', 'Computed Iterations Number(16)', 'Skipped Iterations Number(17)',
#                        'epochs(18)', 'profile(20)', 'CPUs usage(21)', 'Average CPU usage(22)', 'GPUs usage(23)',
#                        'Average GPU Usage(24)', 'usage ratio(25)', 'data_only(26)', 'data time(27)',
#                        'training time(28)', 'test time(29)', 'missing time(31)', 'repetition number(32)', 'path(33)']

irrelevant_column_name = ['starting timestamp(0)', 'starting time(1)', 'tensorflow version(2)', 'system_UUID(3)',
                        'mac_address(4)', 'vm_instance(5)', 'GPU type(6)', 'Network Type(10)', 'classes(12)',
                        'Skipped Iterations Number(17)', 'profile(20)', 'CPUs usage(21)', 'Average CPU usage(22)',
                         'GPUs usage(23)', 'Average GPU Usage(24)', 'usage ratio(25)', 'data_only(26)', 'data time(27)',
                         'test time(29)', 'missing time(31)', 'repetition number(32)', 'path(33)']

[DebugLevel]
# This is for printing the logs. If debug is true, we also print the logs in the DEBUG level. Otherwise,
# only the logs in INFO level is printed.
debug = False


[rf]
n_estimators = [20, 40, 60, 80]
max_features_rf = [auto, sqrt]
max_depth_rf = [10, 20, 30]
min_samples_leaf_rf = [5, 6, 7]
min_samples_split_rf = [2, 5, 10]
bootstrap = [True, False]
kernel = [rbf]
c = [10]
epsilon = [0.1]
gamma = [0.01]
n_neighbors = [5,10]



# variables:
# TR and TE variables related to splitting
[Splitting]
image_nums_train_data = [5, 10, 15]
image_nums_test_data = [20]
core_nums_train_data = [6, 10, 14, 18, 22, 26, 30, 34, 38, 42, 46]
core_nums_test_data = [8, 12, 16, 20, 24, 28, 32, 36, 40, 44, 48]
seed_vector = [1234, 2345, 3456, 4567, 5678, 6789, 7890, 8901, 9012, 1023]
criterion_col_list = ['dataSize','nContainers']
extrapolate = False
feature_extrapolate = ['batch size(13)', 'Real Iterations Number(15)', 'Network depth(11)']
batch size(13) = [8,8]
Real Iterations Number(15) = [320,320]
Network depth(11) = [400,1600]
test_size = 0.2



# Feature selection related variables
[FS]
select_features_vif = False
select_features_sfs = False
SFS_Ridge_param_list = ['alpha_v']
XGBoost = True

min_features = 1
max_features = 2
is_floating = False
fold_num = 5
Confidence_level = 0.999999
clipping_no = 20
ridge_params = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1]
degree = 8


[XGBoost]
param_grid = ['learning_rate_v', 'reg_lambda_v', 'min_child_weight_v', 'max_depth_v']
learning_rate_v = [0.01, 0.1, 0.2, 0.3, 0.4, 0.5]
reg_lambda_v = [1, 2 , 3]
n_estimators_v = [5, 10, 50, 100]
min_child_weight_v = [1, 2, 3]
max_depth_v = [4, 6, 8]
grid_elements = ['learning_rate', 'reg_lambda', 'min_child_weight', 'max_depth']



[Regression]
# regressor variables
regressor_name = lr

[Ridge]
# Ridge params:
ridge_params = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1]

[Lasso]
# Lasso params
lasso_params = [0.1,0.5]

[dt]
# Classifier related variables (DT)
max_features_dt = [sqrt]
max_depth_dt = [7]
min_samples_leaf_dt = [4]
min_samples_split_dt = [5]


[Inverse]
# to_be_inv_List = ['nContainers']
to_be_inv_List = ['GFlops(7)', 'GPU number(9)', 'Network depth(11)', 'batch size(13)', 'Iterations Fraction(14)',
                'Real Iterations Number(15)', 'Computed Iterations Number(16)', 'epochs(18)', 'overall execution time(30)']