Evaluate experiments (sequentially)
<--
Printing results for run 0
Best result for Technique.XGBOOST - Configuration is ['min_child_weight_1', 'gamma_0', 'n_estimators_250', 'learning_rate_0.05', 'max_depth_1'] - (Training MAPE is 0.011759 - HP Selection MAPE is 0.104204) - Validation MAPE is 0.046315
Overall best result is Technique.XGBOOST ['min_child_weight_1', 'gamma_0', 'n_estimators_250', 'learning_rate_0.05', 'max_depth_1']
Metrics for best result:
-->
MAPE: (Training 0.011759 - HP Selection 0.104204) - Validation 0.046315
RMSE: (Training 0.013627 - HP Selection 0.191587) - Validation 0.159775
R^2 : (Training 0.999859 - HP Selection 0.969645) - Validation 0.969768
<--
Building the final regressors
Validation metrics on full dataset for Technique.XGBOOST:
-->
MAPE: 0.045735
RMSE: 0.142282
R^2 : 0.984754
<--
Built the final regressors
Best model:
-->
XGBoost weights: {
    0.708 warm_service_time
    0.292 Lambda
}
<--
